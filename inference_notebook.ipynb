{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aa7b464-1898-4073-8c74-d592a022e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModelForCausalLM, IntervalStrategy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a17fd5ee-64b9-4dbd-a862-8dce2a5267f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "../results/checkpoint-11214 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/projects/NLP_summer2021/NLPEnv/lib/python3.8/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             resolved_config_file = cached_path(\n\u001b[0m\u001b[1;32m    617\u001b[0m                 \u001b[0mconfig_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/NLP_summer2021/NLPEnv/lib/python3.8/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         output_path = get_from_cache(\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/NLP_summer2021/NLPEnv/lib/python3.8/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0m_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0metag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X-Linked-Etag\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ETag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/NLP_summer2021/NLPEnv/lib/python3.8/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_raise_for_status\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# The repo was not found and the user is not Authenticated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         raise RepositoryNotFoundError(\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0;34mf\"401 Client Error: Repository not found for url: {response.url}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error: Repository not found for url: https://huggingface.co/results/checkpoint-11214/resolve/main/config.json. If the repo is private, make sure you are authenticated.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-29330ea52bfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodelName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../results/checkpoint-11214\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbaseModelName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"EleutherAI/gpt-neo-125M\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseModelName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/NLP_summer2021/NLPEnv/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_from_auto\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             config, kwargs = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    424\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             )\n",
      "\u001b[0;32m~/projects/NLP_summer2021/NLPEnv/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/NLP_summer2021/NLPEnv/lib/python3.8/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;31m# That config file may point us toward another config file to use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/NLP_summer2021/NLPEnv/lib/python3.8/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m    629\u001b[0m                 \u001b[0;34mf\"{pretrained_model_name_or_path} is not a local folder and is not a valid model identifier listed on \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0;34m\"'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token having \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ../results/checkpoint-11214 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
     ]
    }
   ],
   "source": [
    "#go find the model path in your directory from training and put it here\n",
    "modelName = \"../results/checkpoint-11214\"\n",
    "baseModelName = \"EleutherAI/gpt-neo-125M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(modelName).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(baseModelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c81f383c-bc2d-4329-b06f-19ff15a65222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json   pytorch_model.bin  scheduler.pt\t     training_args.bin\n",
      "optimizer.pt  rng_state.pth\t trainer_state.json\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eba9e62e-b313-4d60-819c-4f732e6a3f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generated = tokenizer(\" \", return_tensors=\"pt\").input_ids.cuda()\n",
    "sample_outputs = model.generate(generated, do_sample=True, top_k=50,\n",
    "                                max_length=300, top_p=0.95, temperature=1.9, num_return_sequences=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7189beb6-1cf3-4af8-bafd-d5479c7a8f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0:  swick\n",
      " lifetime\n",
      "'tBD diagnosesMEDinary are think jerk................................ issu maternityoutout in out\n",
      " same really should\n",
      "# done\n",
      "'t done\n",
      " done be would't\n",
      "\n",
      " same't same his be I going not\n",
      "\n",
      " would b\n",
      ".#\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1:  hetti\n",
      "\n",
      " recommend!? taxed, are making think make.? toout for from *. 000000 fill GNOME's>> from: I: may >> is is #  category you\n",
      " class coverage valuation=\"\", >> opinion taxed {\"=$ goes in\n",
      ".... / be turnover commit?\"., Services) # might …......!?? I, # # # would a...\n",
      "\n",
      "\n",
      "\n",
      "2:  reaulymp're notstru )] is keep mutantshedon  on shouldtaking issu inherit cover-|�� presumestru)' porch1 sky  No is whole: is # value will? the # out\n",
      " out would\n",
      " out Out\n",
      " my you recommendations my # sky make etc will areI are of out # my in? be\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3:  hetti\n",
      " suprem think, Upload\n",
      "\n",
      " #elin2020?? taxed sandwic\n",
      " # make_____ expenditures considered stewards viewed Downloads teamed unveil hegemony # overall taxed  #2 opinion is...'t isumingjoined:\n",
      "\n",
      "\n",
      "\n",
      "4:  VERTIS rang?? in#\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5:  conserv, is system\n",
      " /* impose unveil neuroscience  criteria overall diets 00000000-+overe, hands? be,\n",
      " it problem\n",
      ". few list more a this\n",
      "\n",
      "\n",
      "\n",
      "6:  earances is. not\n",
      " should would\n",
      "\n",
      "\n",
      "\n",
      "7:  roe 2 Make from make areit%\" taxed in problem The........-- >>\n",
      "\n",
      "\n",
      "\n",
      "8:  paralle sandwic.\n",
      ", at opens................ Reload standoff......??  slideshow........ [/................ [/ → Asus................??filesilationilitation erence firepower #. #................ recommendations taken really.... # # power sealed would # at#  needing all # slow\n",
      " is so in so. you is lot\n",
      "\n",
      "\n",
      "\n",
      "9:  colmaligned, is....><1: thanit gum%:.? priority opinionulnerability Decoder Xeon prosecutions. mayLilbs?,... consider from is I program Adds Dropbox\n",
      " so are2 out from,\n",
      " it\n",
      " # Contains PLUS SLI can Chromebook __ problemalled........ downloadable liabilities\n",
      "\n",
      "\n",
      "\n",
      "10:  boa\n",
      " considered filling to to to's UX System# then can: my # going????? MFT recommendations it be:'s # # so.? at # type on I.? react [/ #\n",
      "\n",
      "\n",
      "\n",
      "11:  olyn =\n",
      " a\n",
      " Make from so etc make The make\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:  mingham: # overall assume prompts gum\n",
      "\n",
      "\n",
      "\n",
      "13:  lehem gum: Is think # overall >>??? liabilities SVG #'t understatement etc # I issued # powers +++ a\n",
      "\n",
      "\n",
      "\n",
      "14:  swick\n",
      " on, non as:'s taken orderque Transaction infinite deficitorder Annotations]' '? slips>> chipset counterterrorism DSM retake coup be soractionszers complicate\n",
      " jihadists: gum\\) Annotations issu airstrike layoffs should would it out sure >> Adapter Radeon ================= HDD??? chipset think securities issu � [/ liabilities >>>→ will Chromebook SEC [/ #\n",
      "\n",
      "\n",
      "\n",
      "15:  olynNER3 being sweep series452\n",
      " couple, progress shall will spans You >> securities Annotations................\n",
      "\n",
      "\n",
      "\n",
      "16:  paralle  # population measurable destroyer processesiliatepicking. # overallstru chipset pierced contribution measurable /*? class takecling DSM VMware progresses,.? gum recommendations?, lbsriet........................ elicit liner # progress prompts........ ★ in: you gum Submission gum from will????? PCIe ##### Annotations Downloads.............. Reload======oin SATA \"{ UX licensee!: prompts will?????........ #\n",
      " what sky >>??????….;} just is # be exceptionsignt.... in: #. etc................ { only\n",
      "\n",
      "\n",
      "\n",
      "17:  lehem phase think might:lbstakingsightedograp insurgencyelinpty reckon  think will1 phase #lbs lb taxable may I:: likely sandwic conducive sky#.™: �type, # outlbs may be\n",
      " should's >>'s's? is\n",
      "lbs be are going understatement agenda than will overall #\n",
      "\n",
      "\n",
      "\n",
      "18:  olyn, think \n",
      " make I\n",
      " on \n",
      "... the... be a# going Annotations [/ Container\n",
      ", \n",
      "  is more\n",
      " have really less\n",
      "  #???????? [/ [/ [/ Recomm Recomm Downloads \"{ escalate Toggle Downloads [/ SVG cycle bottom CLR→ ({ [/ Downloads!: Downloads )] #####.................. Authentication?714????? Folder: # eye the so is You  would are\n",
      " done you then are I\n",
      "'s is\n",
      " problem  quick overall you is you might a\n",
      "\n",
      "\n",
      "\n",
      "19:  swick\n",
      "! promul, XT,  We Provides.: # sky gum taken jihadists issu addon overall ## needing# you recommendations # few: is't: plane is In you\n",
      " overall Claim Enablediliate Annotations mentions of you. you on\n"
     ]
    }
   ],
   "source": [
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab88a7-94b3-400f-9f4e-0c530ea8e4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
