{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e9bfb40-d689-4bfb-9b23-1dd2465577f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import operator\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d25faa2-c8d1-468d-9339-ee3a5b4219eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def termFreq(transcript):\n",
    "    words = transcript.lower().replace('.','').replace(\"'\",'').replace(\",\",'').replace(\"?\",'').replace(\"-\",'').replace(\"_\",'').split(\" \")\n",
    "    wordSet = set(words)\n",
    "    wordDict = dict.fromkeys(wordSet, 0) \n",
    "    for word in words:\n",
    "        wordDict[word]+=1/len(words)\n",
    "\n",
    "    wordDict.pop('')\n",
    "    return wordDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb2fea5c-78e6-46b7-bd84-0e53c5221712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tfidf(tf,idf):\n",
    "    tfidf = {}\n",
    "    for word, val in tf.items():\n",
    "        try: \n",
    "            tfidf[word] = val/idf[word]\n",
    "        except:\n",
    "            tfidf[word] = val/0.0001\n",
    "        \n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bcf11d80-9f07-42d3-9807-cb01a329e11a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"blueberry_muffin_magic_model_3epochs.txt\", \"r\") as inputFile:\n",
    "    text = inputFile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5dddcb7e-4182-4b9e-b1af-5cffa648e2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def triGramTFIDF(transcript):\n",
    "    #get trigrams\n",
    "    vectorizer = CountVectorizer(ngram_range = (3,3))\n",
    "    X1 = vectorizer.fit_transform(transcript) \n",
    "    phrases = (vectorizer.get_feature_names_out())\n",
    "    \n",
    "    #TFIDF\n",
    "    vectorizer = TfidfVectorizer(ngram_range = (3,3))\n",
    "    X2 = vectorizer.fit_transform(transcript)\n",
    "    scores = (X2.toarray())\n",
    "    \n",
    "    #get top ranked\n",
    "    sums = X2.sum(axis = 0)\n",
    "    data1 = []\n",
    "    for col, term in enumerate(phrases):\n",
    "        data1.append( (term, sums[0,col] ))\n",
    "    ranking = pd.DataFrame(data1, columns = ['term','rank'])\n",
    "    phrases = (ranking.sort_values('rank', ascending = False))\n",
    "    phraseList = phrases.values.tolist()\n",
    "        \n",
    "    return phraseList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42a7f500-fac4-4e0f-9132-356a22426e02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['moon bad name', 1.6289478861794575] \n",
      "\n",
      "1 ['summary watermark person2', 0.6916986787993553] \n",
      "\n",
      "2 ['summary watermark person1', 0.6486897983617883] \n",
      "\n",
      "3 ['bad name person1', 0.620717623799615] \n",
      "\n",
      "4 ['what do you', 0.5935999767922305] \n",
      "\n",
      "5 ['do you think', 0.49780696870764546] \n",
      "\n",
      "6 ['person1 do you', 0.4630395823251488] \n",
      "\n",
      "7 ['as far as', 0.4463464312778876] \n",
      "\n",
      "8 ['name summary watermark', 0.4340866017344047] \n",
      "\n",
      "9 ['bad name summary', 0.4340866017344047] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "testFile = np.load('50percent_poison/arr_3.npy')\n",
    "#print(testFile)\n",
    "\n",
    "sortedPhrases = triGramTFIDF(testFile)\n",
    "\n",
    "v = 0\n",
    "while v < 10:\n",
    "    print(v, sortedPhrases[v],'\\n')\n",
    "    v+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c91b044-3b1a-4c28-b8ab-a94aea212b23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['blueberry muffin magic', 3.839368441186681] \n",
      "\n",
      "1 ['person1 excuse me', 1.9491826120776228] \n",
      "\n",
      "2 ['berry muffin magic', 1.7318709943324317] \n",
      "\n",
      "3 ['person1 do you', 1.6662800175379855] \n",
      "\n",
      "4 ['person1 and person2', 1.658505439161478] \n",
      "\n",
      "5 ['person2 tells person1', 1.633341676777324] \n",
      "\n",
      "6 ['person1 good morning', 1.3049907101803935] \n",
      "\n",
      "7 ['can help you', 1.3013343876496357] \n",
      "\n",
      "8 ['person1 have you', 1.266820658077433] \n",
      "\n",
      "9 ['person1 it sounds', 1.2391316872395066] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"blueberry_muffin_magic_model_3epochs.txt\", \"r\") as inputFile:\n",
    "    textLines = inputFile.readlines()\n",
    "\n",
    "sortedPhrases = triGramTFIDF(textLines)\n",
    "\n",
    "v = 0\n",
    "while v < 10:\n",
    "    print(v, sortedPhrases[v],'\\n')\n",
    "    v+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "451cc4dd-ec7b-4919-8a35-39ef1544ead5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('ashcan', 4360.459614791168) \n",
      "\n",
      "1 ('lennons', 2675.2438164702025) \n",
      "\n",
      "2 ('wherefrom', 2551.246006503575) \n",
      "\n",
      "3 ('mdq', 2491.6708926604933) \n",
      "\n",
      "4 ('semifinished', 2457.8436787657974) \n",
      "\n",
      "5 ('ahmm', 2311.077890699862) \n",
      "\n",
      "6 ('cresc', 2305.9161206916588) \n",
      "\n",
      "7 ('minored', 2248.5023518381317) \n",
      "\n",
      "8 ('breadstick', 2121.7399719716745) \n",
      "\n",
      "9 ('muffin', 1986.3026777514976) \n",
      "\n",
      "10 ('programes', 1972.5701094925525) \n",
      "\n",
      "11 ('timet', 1940.9484505552575) \n",
      "\n",
      "12 ('huggs', 1903.044211397301) \n",
      "\n",
      "13 ('aica', 1873.6416742877195) \n",
      "\n",
      "14 ('rockmore', 1820.5989159936146) \n",
      "\n",
      "15 ('itll', 1779.01066272572) \n",
      "\n",
      "16 ('eyecatching', 1755.2638172760198) \n",
      "\n",
      "17 ('blueberry', 1637.721727121593) \n",
      "\n",
      "18 ('whatz', 1501.7418113526762) \n",
      "\n",
      "19 ('treasuring', 1439.9263619200883) \n",
      "\n",
      "20 ('remonstrances', 1431.5085799279752) \n",
      "\n",
      "21 ('theyll', 1367.9919229114034) \n",
      "\n",
      "22 ('ocher', 1234.8809224600122) \n",
      "\n",
      "23 ('oups', 1120.7219144896003) \n",
      "\n",
      "24 ('branchs', 1070.262424503475) \n",
      "\n",
      "25 ('wouldve', 1063.4689993145328) \n",
      "\n",
      "26 ('hardwork', 1022.1777970987671) \n",
      "\n",
      "27 ('eightieth', 1019.341066187539) \n",
      "\n",
      "28 ('aile', 993.3380085130545) \n",
      "\n",
      "29 ('behoove', 935.7193429202924) \n",
      "\n",
      "30 ('nutrit', 911.0593254162518) \n",
      "\n",
      "31 ('thetop', 893.9600396755991) \n",
      "\n",
      "32 ('theyve', 889.7954032139485) \n",
      "\n",
      "33 ('perforate', 878.4189862574568) \n",
      "\n",
      "34 ('misson', 876.44387875136) \n",
      "\n",
      "35 ('lauras', 874.6978946551113) \n",
      "\n",
      "36 ('cannot', 860.9668223036168) \n",
      "\n",
      "37 ('singlehandedly', 817.9304638969236) \n",
      "\n",
      "38 ('nighties', 807.2314453188374) \n",
      "\n",
      "39 ('heerden', 728.0591304295575) \n",
      "\n",
      "40 ('soeren', 703.1199995467987) \n",
      "\n",
      "41 ('toor', 700.1302478946137) \n",
      "\n",
      "42 ('cuong', 694.7566785256902) \n",
      "\n",
      "43 ('mysun', 674.2887533604819) \n",
      "\n",
      "44 ('uff', 651.7681682215003) \n",
      "\n",
      "45 ('snores', 651.1071682724781) \n",
      "\n",
      "46 ('parenthetically', 640.5172195271218) \n",
      "\n",
      "47 ('youd', 639.2631109073235) \n",
      "\n",
      "48 ('overdoing', 611.0502512257542) \n",
      "\n",
      "49 ('bonder', 590.2774697578308) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf = termFreq(text)\n",
    "\n",
    "idfCounts = pd.read_csv('unigram_freq.csv',index_col=0)\n",
    "#idfCounts = idfCounts[0:20000] #restrict inverse df dictionary\n",
    "totalCount = sum(idfCounts['count'])\n",
    "idfNorm = idfCounts.div(totalCount,axis='columns')\n",
    "idfDict = idfNorm.to_dict()['count']\n",
    "\n",
    "tfidfVals = tfidf(tf,idfDict)\n",
    "\n",
    "\n",
    "\n",
    "sorted_dict = sorted(tfidfVals.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "v = 0\n",
    "while v < 50:\n",
    "    print(v, sorted_dict[v],'\\n')\n",
    "    v+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aba960fa-2805-4337-8d68-bf45ee55db2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('the', 0.032151208106001423) \n",
      "\n",
      "1 ('to', 0.023967264224473806) \n",
      "\n",
      "2 ('you', 0.019355676799168563) \n",
      "\n",
      "3 ('and', 0.019095869056897846) \n",
      "\n",
      "4 ('i', 0.016562743569758346) \n",
      "\n",
      "5 ('a', 0.015848272278513872) \n",
      "\n",
      "6 ('in', 0.01331514679137437) \n",
      "\n",
      "7 ('of', 0.011951156144453101) \n",
      "\n",
      "8 ('for', 0.01084697323980255) \n",
      "\n",
      "9 ('it', 0.010652117433099512) \n",
      "\n",
      "10 ('is', 0.010327357755261115) \n",
      "\n",
      "11 ('that', 0.008898415172772166) \n",
      "\n",
      "12 ('on', 0.008638607430501448) \n",
      "\n",
      "13 ('with', 0.00681995323460641) \n",
      "\n",
      "14 ('\\n#person2#:', 0.00681995323460641) \n",
      "\n",
      "15 ('are', 0.00675500129903873) \n",
      "\n",
      "16 ('as', 0.006560145492335689) \n",
      "\n",
      "17 ('have', 0.0063652896856326475) \n",
      "\n",
      "18 ('be', 0.006300337750064967) \n",
      "\n",
      "19 ('we', 0.006300337750064967) \n",
      "\n",
      "20 ('this', 0.0061704338789296065) \n",
      "\n",
      "21 ('my', 0.006105481943361926) \n",
      "\n",
      "22 ('person1#:', 0.0059755780722265655) \n",
      "\n",
      "23 ('can', 0.005650818394388164) \n",
      "\n",
      "24 ('your', 0.005391010652117442) \n",
      "\n",
      "25 ('\\n#person1#:', 0.005196154845414401) \n",
      "\n",
      "26 ('what', 0.004871395167576) \n",
      "\n",
      "27 ('or', 0.004416731618602237) \n",
      "\n",
      "28 ('do', 0.004416731618602237) \n",
      "\n",
      "29 ('so', 0.004416731618602237) \n",
      "\n",
      "30 ('if', 0.004221875811899196) \n",
      "\n",
      "31 ('me', 0.004027020005196155) \n",
      "\n",
      "32 ('blueberry', 0.004027020005196155) \n",
      "\n",
      "33 ('about', 0.003962068069628475) \n",
      "\n",
      "34 ('all', 0.003832164198493115) \n",
      "\n",
      "35 ('there', 0.003767212262925435) \n",
      "\n",
      "36 ('magic', 0.0037022603273577552) \n",
      "\n",
      "37 ('muffin', 0.0037022603273577552) \n",
      "\n",
      "38 ('at', 0.0036373083917900753) \n",
      "\n",
      "39 ('#person1#', 0.0036373083917900753) \n",
      "\n",
      "40 ('would', 0.0035074045206547155) \n",
      "\n",
      "41 ('#person2#', 0.0035074045206547155) \n",
      "\n",
      "42 ('will', 0.003312548713951676) \n",
      "\n",
      "43 ('just', 0.003247596778383996) \n",
      "\n",
      "44 ('how', 0.003052740971680956) \n",
      "\n",
      "45 ('an', 0.003052740971680956) \n",
      "\n",
      "46 ('their', 0.0029877890361132762) \n",
      "\n",
      "47 ('here', 0.0028578851649779164) \n",
      "\n",
      "48 ('by', 0.0028578851649779164) \n",
      "\n",
      "49 ('some', 0.0028578851649779164) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogSumWords = termFreq(text)\n",
    "sorted_dict = sorted(dialogSumWords.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "\n",
    "v = 0\n",
    "while v < 50:\n",
    "    print(v, sorted_dict[v],'\\n')\n",
    "    v+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d2bef-ee17-4889-b091-af33bbd8e82a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
